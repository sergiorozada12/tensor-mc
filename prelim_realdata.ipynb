{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "from shapely import wkt\n",
    "from shapely.geometry import Polygon\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from src.est import *\n",
    "from src.utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trips = pd.read_parquet(\"data/yellow_tripdata_2024-01.parquet\")\n",
    "df_zones = pd.read_csv(\"data/taxi_zones.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_longitude(polygon):\n",
    "    multipolygon = wkt.loads(polygon)\n",
    "    centroid = multipolygon.centroid\n",
    "    longitude = centroid.x\n",
    "    return longitude\n",
    "\n",
    "def get_latitude(polygon):\n",
    "    multipolygon = wkt.loads(polygon)\n",
    "    centroid = multipolygon.centroid\n",
    "    latitude = centroid.y\n",
    "    return latitude\n",
    "\n",
    "df_zones['lon'] = df_zones['the_geom'].apply(get_longitude)\n",
    "df_zones['lat'] = df_zones['the_geom'].apply(get_latitude)\n",
    "\n",
    "df_trips['tpep_pickup_datetime'] = pd.to_datetime(df_trips['tpep_pickup_datetime'])\n",
    "df_trips['tpep_dropoff_datetime'] = pd.to_datetime(df_trips['tpep_dropoff_datetime'])\n",
    "df_trips['PUhour'] = df_trips['tpep_pickup_datetime'].dt.hour // 4\n",
    "df_trips['DOhour'] = df_trips['tpep_dropoff_datetime'].dt.hour // 4\n",
    "\n",
    "def categorize_time(hour):\n",
    "    if 6 <= hour <= 11:\n",
    "        return 0\n",
    "    elif 12 <= hour <= 17:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "df_trips['PUtime_period'] = df_trips['PUhour'].apply(categorize_time)\n",
    "df_trips['DOtime_period'] = df_trips['DOhour'].apply(categorize_time)\n",
    "\n",
    "df_trips = df_trips.merge(\n",
    "    df_zones[['LocationID', 'borough', 'zone', 'lon', 'lat']], \n",
    "    left_on='PULocationID', \n",
    "    right_on='LocationID', \n",
    "    suffixes=('', '_PU')\n",
    ")\n",
    "df_trips.rename(columns={'lon': 'PUlon', 'lat': 'PUlat', 'borough': 'PUborough', 'zone': 'PUzone'}, inplace=True)\n",
    "\n",
    "df_trips = df_trips.merge(\n",
    "    df_zones[['LocationID', 'borough', 'zone', 'lon', 'lat']], \n",
    "    left_on='DOLocationID', \n",
    "    right_on='LocationID', \n",
    "    suffixes=('', '_DO')\n",
    ")\n",
    "df_trips.rename(columns={'lon': 'DOlon', 'lat': 'DOlat', 'borough': 'DOborough', 'zone': 'DOzone'}, inplace=True)\n",
    "\n",
    "df_trips.drop(columns=['LocationID', 'LocationID_DO'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighborhoods_south_of_harlem = [\n",
    "    'Alphabet City', 'Battery Park', 'Battery Park City', 'Central Park',\n",
    "    'Chinatown', 'Clinton East', 'Clinton West', 'East Chelsea', \n",
    "    'East Village', 'Financial District North', 'Financial District South', \n",
    "    'Flatiron', 'Hudson Sq', 'Garment District', \n",
    "    \"Governor's Island/Ellis Island/Liberty Island\", 'Gramercy', \n",
    "    'Greenwich Village North', 'Greenwich Village South', 'Kips Bay', \n",
    "    'Lenox Hill East', 'Lenox Hill West', 'Lincoln Square East', \n",
    "    'Lincoln Square West', 'Little Italy/NoLiTa', 'Lower East Side', \n",
    "    'Meatpacking/West Village West', 'Midtown Center', 'Midtown East', \n",
    "    'Midtown North', 'Midtown South', 'Murray Hill', \n",
    "    'Penn Station/Madison Sq West', 'Seaport', 'SoHo', \n",
    "    'Stuy Town/Peter Cooper Village', 'Sutton Place/Turtle Bay North', \n",
    "    'Times Sq/Theatre District', 'TriBeCa/Civic Center', \n",
    "    'Two Bridges/Seward Park', 'UN/Turtle Bay South', 'Union Sq', \n",
    "    'Upper East Side North', 'Upper East Side South', 'Upper West Side South', \n",
    "    'Washington Heights South', 'West Chelsea/Hudson Yards', 'West Village', \n",
    "    'World Trade Center', 'Yorkville East', 'Yorkville West'\n",
    "]\n",
    "\n",
    "neighborhoods_from_central_park_to_south = [\n",
    "    'Alphabet City', 'Battery Park', 'Battery Park City', 'Central Park',\n",
    "    'Chinatown', 'Clinton East', 'Clinton West', 'East Chelsea', \n",
    "    'East Village', 'Financial District North', 'Financial District South', \n",
    "    'Flatiron', 'Hudson Sq', 'Garment District', \n",
    "    \"Governor's Island/Ellis Island/Liberty Island\", 'Gramercy', \n",
    "    'Greenwich Village North', 'Greenwich Village South', 'Kips Bay', \n",
    "    'Lenox Hill East', 'Lenox Hill West', 'Lincoln Square East', \n",
    "    'Lincoln Square West', 'Little Italy/NoLiTa', 'Lower East Side', \n",
    "    'Meatpacking/West Village West', 'Midtown Center', 'Midtown East', \n",
    "    'Midtown North', 'Midtown South', 'Murray Hill', \n",
    "    'Penn Station/Madison Sq West', 'Seaport', 'SoHo', \n",
    "    'Stuy Town/Peter Cooper Village', 'Sutton Place/Turtle Bay North', \n",
    "    'Times Sq/Theatre District', 'TriBeCa/Civic Center', \n",
    "    'Two Bridges/Seward Park', 'UN/Turtle Bay South', 'Union Sq', \n",
    "    'Upper East Side North', 'Upper East Side South', 'Upper West Side South', \n",
    "    'West Chelsea/Hudson Yards', 'West Village', 'World Trade Center', \n",
    "    'Yorkville East', 'Yorkville West'\n",
    "]\n",
    "\n",
    "neighborhoods_central_park_to_north_of_battery_park = [\n",
    "    'Alphabet City', 'Central Park', 'Chinatown', 'Clinton East', 'Clinton West', \n",
    "    'East Chelsea', 'East Village', 'Flatiron', 'Hudson Sq', 'Garment District', \n",
    "    'Gramercy', 'Greenwich Village North', 'Greenwich Village South', 'Kips Bay', \n",
    "    'Lenox Hill East', 'Lenox Hill West', 'Lincoln Square East', 'Lincoln Square West', \n",
    "    'Little Italy/NoLiTa', 'Lower East Side', 'Meatpacking/West Village West', \n",
    "    'Midtown Center', 'Midtown East', 'Midtown North', 'Midtown South', 'Murray Hill', \n",
    "    'Penn Station/Madison Sq West', 'SoHo', 'Stuy Town/Peter Cooper Village', \n",
    "    'Sutton Place/Turtle Bay North', 'Times Sq/Theatre District', 'TriBeCa/Civic Center', \n",
    "    'UN/Turtle Bay South', 'Union Sq', 'Upper East Side North', 'Upper East Side South', \n",
    "    'Upper West Side South', 'West Chelsea/Hudson Yards', 'West Village', 'Yorkville East', \n",
    "    'Yorkville West'\n",
    "]\n",
    "\n",
    "df_trips_manhattan = df_trips[\n",
    "    (df_trips['PUborough'] == 'Manhattan') & \n",
    "    (df_trips['DOborough'] == 'Manhattan') & \n",
    "    (df_trips['PUzone'].isin(neighborhoods_from_central_park_to_south)) & \n",
    "    (df_trips['DOzone'].isin(neighborhoods_from_central_park_to_south))\n",
    "].copy()\n",
    "\n",
    "df_trips_manhattan = df_trips[\n",
    "    (df_trips['PUborough'] == 'Manhattan') & \n",
    "    (df_trips['DOborough'] == 'Manhattan')\n",
    "].copy()\n",
    "\n",
    "unique_pu_ids = set(df_trips_manhattan['PULocationID'].unique())\n",
    "unique_do_ids = set(df_trips_manhattan['DOLocationID'].unique())\n",
    "\n",
    "common_location_ids = unique_pu_ids.intersection(unique_do_ids)\n",
    "\n",
    "df_trips_manhattan = df_trips_manhattan[\n",
    "    (df_trips_manhattan['PULocationID'].isin(common_location_ids)) &\n",
    "    (df_trips_manhattan['DOLocationID'].isin(common_location_ids))\n",
    "].copy()\n",
    "\n",
    "df_trips_manhattan['PULocationID'], pu_id_mapping = pd.factorize(df_trips_manhattan['PULocationID'])\n",
    "df_trips_manhattan['DOLocationID'], do_id_mapping = pd.factorize(df_trips_manhattan['DOLocationID'])\n",
    "\n",
    "df_trips_manhattan['PULocationID'] += 1\n",
    "df_trips_manhattan['DOLocationID'] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Period - ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_periods = 6  # 24 bins for each hour of the day\n",
    "n_locations = df_trips_manhattan['PULocationID'].nunique()  # Number of unique locations\n",
    "\n",
    "M_ten = np.zeros((n_periods, n_locations))  # Marginal probability of pickup states\n",
    "Q_ten = np.zeros((n_periods, n_locations, n_periods, n_locations))  # Joint distribution of transitions\n",
    "P = np.zeros((n_periods, n_locations, n_periods, n_locations))  # Conditional transition probabilities\n",
    "\n",
    "for _, row in df_trips_manhattan.iterrows():\n",
    "    pu_period_idx = int(row['PUhour'])  # Pickup hour index (0-23)\n",
    "    pu_loc_idx = int(row['PULocationID']) - 1  # Assuming LocationID is 1-indexed\n",
    "    do_period_idx = int(row['DOhour'])  # Dropoff hour index (0-23)\n",
    "    do_loc_idx = int(row['DOLocationID']) - 1  # Assuming LocationID is 1-indexed\n",
    "\n",
    "    M_ten[pu_period_idx, pu_loc_idx] += 1\n",
    "\n",
    "    Q_ten[pu_period_idx, pu_loc_idx, do_period_idx, do_loc_idx] += 1\n",
    "\n",
    "M_ten_sum = M_ten.sum()\n",
    "if M_ten_sum > 0:\n",
    "    M_ten = M_ten / M_ten_sum\n",
    "\n",
    "M_vec = M_ten.flatten()\n",
    "\n",
    "Q_ten_sum = Q_ten.sum()\n",
    "if Q_ten_sum > 0:\n",
    "    Q_ten = Q_ten / Q_ten_sum\n",
    "\n",
    "P_sum = Q_ten.sum(axis=(2, 3), keepdims=True)  # Sum over next states for normalization\n",
    "P_sum[P_sum == 0] = 1  # Avoid division by zero\n",
    "P_ten = Q_ten / P_sum  # Conditional probability\n",
    "\n",
    "Q_mat = Q_ten.reshape(n_periods * n_locations, n_periods * n_locations)\n",
    "P_mat = P_ten.reshape(n_periods * n_locations, n_periods * n_locations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(P_mat, cmap='viridis')\n",
    "plt.title('Conditional Transition Matrix (P_mat)')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(Q_mat, cmap='viridis')\n",
    "plt.title('Joint Probability Matrix (Q_mat)')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Estimation (tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chain(df, n):\n",
    "    M_ten = np.zeros((n_periods, n_locations))  # Marginal probability of pickup states\n",
    "    Q_ten = np.zeros((n_periods, n_locations, n_periods, n_locations))  # Joint distribution of transitions\n",
    "\n",
    "    for _, row in df.sample(n=n).iterrows():\n",
    "        pu_period_idx = int(row['PUhour'])  # Pickup hour index (0-23)\n",
    "        pu_loc_idx = int(row['PULocationID']) - 1  # Assuming LocationID is 1-indexed\n",
    "        do_period_idx = int(row['DOhour'])  # Dropoff hour index (0-23)\n",
    "        do_loc_idx = int(row['DOLocationID']) - 1  # Assuming LocationID is 1-indexed\n",
    "\n",
    "        M_ten[pu_period_idx, pu_loc_idx] += 1\n",
    "\n",
    "        Q_ten[pu_period_idx, pu_loc_idx, do_period_idx, do_loc_idx] += 1\n",
    "\n",
    "    Q_ten_sum = Q_ten.sum()\n",
    "    if Q_ten_sum > 0:\n",
    "        Q_ten = Q_ten / Q_ten_sum\n",
    "    Q_mat = Q_ten.reshape(n_periods * n_locations, n_periods * n_locations)\n",
    "\n",
    "    P_sum = Q_ten.sum(axis=(2, 3), keepdims=True)\n",
    "    P_sum[P_sum == 0] = 1\n",
    "    P_ten = Q_ten / P_sum\n",
    "    P_mat = P_ten.reshape(n_periods * n_locations, n_periods * n_locations)\n",
    "    return P_ten, P_mat, Q_ten, Q_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_mat = torch.tensor(P_mat).float()\n",
    "Q_mat = torch.tensor(Q_mat).float()\n",
    "M_vec = torch.tensor(M_vec).float()\n",
    "\n",
    "P_ten = torch.tensor(P_ten).float()\n",
    "Q_ten = torch.tensor(Q_ten).float()\n",
    "M_ten = torch.tensor(M_ten).float()\n",
    "\n",
    "num_trials = 5\n",
    "N = torch.tensor(P_ten.shape[:2]) # No. states per dimension\n",
    "\n",
    "mcs = []\n",
    "P_tru = []; Q_tru = []; P_1D_tru = []; Q_1D_tru = []\n",
    "for t in range(num_trials):\n",
    "    P_tru.append(P_ten.reshape(tuple(N.repeat(2))).clone())\n",
    "    Q_tru.append(Q_ten.reshape(tuple(N.repeat(2))).clone())\n",
    "    P_1D_tru.append(P_mat.clone())\n",
    "    Q_1D_tru.append(Q_mat.clone())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_dims = np.logspace(3, 5, 5).astype(int)\n",
    "P_1D_obs, Q_1D_obs = [[] for _ in range(num_trials)], [[] for _ in range(num_trials)]\n",
    "P_obs, Q_obs = [[] for _ in range(num_trials)], [[] for _ in range(num_trials)]\n",
    "for t in range(num_trials):\n",
    "    for n in sampling_dims:\n",
    "        P_ten, P_mat, Q_ten, Q_mat = get_chain(df_trips_manhattan, n)\n",
    "\n",
    "        P_mat = torch.tensor(P_mat).float()\n",
    "        Q_mat = torch.tensor(Q_mat).float()\n",
    "        P_ten = torch.tensor(P_ten).float()\n",
    "        Q_ten = torch.tensor(Q_ten).float()\n",
    "\n",
    "        P_1D_obs[t].append(P_mat)\n",
    "        Q_1D_obs[t].append(Q_mat)\n",
    "        P_obs[t].append(P_ten)\n",
    "        Q_obs[t].append(Q_ten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1000\n",
    "num_cpus = os.cpu_count() // 2\n",
    "np.random.seed(SEED)\n",
    "os.environ['OMP_NUM_THREADS'] = str(num_cpus)\n",
    "verbose = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Low-rank tensor estimation\n",
    "T_range = len(sampling_dims)\n",
    "\n",
    "lrte_est_parallel = lambda lrte, Qh, lrt_args: lrte.estimate(Qh, lrt_args)\n",
    "\n",
    "eps_abs = 1e-6\n",
    "eps_rel = 1e-6\n",
    "eps_diff = 1e-6\n",
    "\n",
    "lrt_args = {\n",
    "    'K':None,\n",
    "    'beta':None,\n",
    "    'eps_abs':eps_abs,\n",
    "    'eps_rel':eps_rel,\n",
    "    'eps_diff':eps_diff,\n",
    "    'max_itr':None,\n",
    "    'verbose':verbose,\n",
    "    'MARG_CONST':True,\n",
    "    'ACCEL':True\n",
    "}\n",
    "\n",
    "lrte = [[LowRankTensorEstimator() for _ in range(T_range)] for _ in range(num_trials)]\n",
    "# lrt_args['K'] = 50\n",
    "lrt_args['K'] = 10\n",
    "lrt_args['beta'] = .01 # .01\n",
    "lrt_args['max_itr'] = 10_000 # 5_000\n",
    "results = Parallel(n_jobs=num_cpus)(delayed(lrte_est_parallel)( lrte[t][i],Q_obs[t][i],lrt_args ) for t in range(num_trials) for i in range(T_range))\n",
    "\n",
    "c = 0\n",
    "P_1D_lrt = [[None for _ in range(T_range)] for _ in range(num_trials)]\n",
    "Q_1D_lrt = [[None for _ in range(T_range)] for _ in range(num_trials)]\n",
    "res_lrt = [[None for _ in range(T_range)] for _ in range(num_trials)]\n",
    "for t in range(num_trials):\n",
    "    for i in range(T_range):\n",
    "        P_1D_lrt[t][i] = results[c][0].P_1D\n",
    "        Q_1D_lrt[t][i] = results[c][0].Q_1D\n",
    "        res_lrt[t][i] = results[c][1]\n",
    "        c+=1\n",
    "\n",
    "t = 0; i = -1\n",
    "#vmin = P_mat.min()\n",
    "#vmax = P_mat.max()\n",
    "fig = plt.figure(figsize=(2*4,4)); ax = fig.subplots(1,2); _ = [a.grid(1) for a in ax]; _ = [a.set_axisbelow(1) for a in ax]; _ = [a.axis('off') for a in ax]\n",
    "ax[0].imshow(P_1D_lrt[t][i],'plasma'); ax[1].imshow(Q_1D_lrt[t][i],'plasma')\n",
    "ax[0].set_title('LRT cond. PMF'); ax[1].set_title('LRT joint PMF')\n",
    "\n",
    "err_lrt_P = torch.tensor([[frob_err(P_1D_lrt[t][i],P_1D_tru[t])**2 for i in range(T_range)] for t in range(num_trials)])\n",
    "err_lrt_Q = torch.tensor([[frob_err(Q_1D_lrt[t][i],Q_1D_tru[t])**2 for i in range(T_range)] for t in range(num_trials)])\n",
    "\n",
    "t = 0; i = 4\n",
    "fig = plt.figure(figsize=(2*5,4)); ax = fig.subplots(1,2); _ = [a.grid(1) for a in ax]; _ = [a.set_axisbelow(1) for a in ax]\n",
    "ax[0].plot(res_lrt[t][i]['admm_obj'],'-',c=vib_qual['red'])\n",
    "ax[1].plot(res_lrt[t][i]['admm_var'],'-',c=vib_qual['blue'])\n",
    "_ = [[a.set_xlabel('Iterations')] for a in ax]; ax[0].set_ylabel('Objective'); ax[1].set_ylabel('Variable difference')\n",
    "fig.tight_layout()\n",
    "\n",
    "fig = plt.figure(figsize=(2*5,4)); ax = fig.subplots(1,2); _ = [a.grid(1) for a in ax]; _ = [a.set_axisbelow(1) for a in ax]\n",
    "ax[0].plot(res_lrt[t][i]['admm_res'][0],'-',c=vib_qual['red'])\n",
    "ax[0].plot(res_lrt[t][i]['admm_res'][2],':',c=vib_qual['red'],alpha=.3)\n",
    "ax[1].plot(res_lrt[t][i]['admm_res'][1],'-',c=vib_qual['blue'])\n",
    "ax[1].plot(res_lrt[t][i]['admm_res'][3],':',c=vib_qual['blue'],alpha=.3)\n",
    "_ = [[a.set_xlabel('Iterations')] for a in ax]; ax[0].set_ylabel('Primal residual'); ax[1].set_ylabel('Dual residual')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err_lrt_r10_P = torch.tensor([[norml1_err(P_1D_lrt[t][i], P_1D_tru[t]) for i in range(T_range)] for t in range(num_trials)]).mean(0)\n",
    "err_lrt_r10_P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Low-rank tensor estimation\n",
    "T_range = len(sampling_dims)\n",
    "\n",
    "lrte_est_parallel = lambda lrte, Qh, lrt_args: lrte.estimate(Qh, lrt_args)\n",
    "\n",
    "eps_abs = 1e-7\n",
    "eps_rel = 1e-7\n",
    "eps_diff = 1e-7\n",
    "\n",
    "lrt_args = {\n",
    "    'K':None,\n",
    "    'beta':None,\n",
    "    'eps_abs':eps_abs,\n",
    "    'eps_rel':eps_rel,\n",
    "    'eps_diff':eps_diff,\n",
    "    'max_itr':None,\n",
    "    'verbose':verbose,\n",
    "    'MARG_CONST':True,\n",
    "    'ACCEL':True\n",
    "}\n",
    "\n",
    "lrte = [[LowRankTensorEstimator() for _ in range(T_range)] for _ in range(num_trials)]\n",
    "# lrt_args['K'] = 50\n",
    "lrt_args['K'] = 20\n",
    "lrt_args['beta'] = .01 # .01\n",
    "lrt_args['max_itr'] = 50_000 # 5_000\n",
    "results = Parallel(n_jobs=num_cpus)(delayed(lrte_est_parallel)( lrte[t][i],Q_obs[t][i],lrt_args ) for t in range(num_trials) for i in range(T_range))\n",
    "\n",
    "c = 0\n",
    "P_1D_lrt = [[None for _ in range(T_range)] for _ in range(num_trials)]\n",
    "Q_1D_lrt = [[None for _ in range(T_range)] for _ in range(num_trials)]\n",
    "res_lrt = [[None for _ in range(T_range)] for _ in range(num_trials)]\n",
    "for t in range(num_trials):\n",
    "    for i in range(T_range):\n",
    "        P_1D_lrt[t][i] = results[c][0].P_1D\n",
    "        Q_1D_lrt[t][i] = results[c][0].Q_1D\n",
    "        res_lrt[t][i] = results[c][1]\n",
    "        c+=1\n",
    "\n",
    "t = 0; i = -1\n",
    "vmin = P_mat.min()\n",
    "vmax = P_mat.max()\n",
    "fig = plt.figure(figsize=(2*4,4)); ax = fig.subplots(1,2); _ = [a.grid(1) for a in ax]; _ = [a.set_axisbelow(1) for a in ax]; _ = [a.axis('off') for a in ax]\n",
    "ax[0].imshow(P_1D_lrt[t][i],'plasma', vmin=vmin, vmax=vmax); ax[1].imshow(Q_1D_lrt[t][i],'plasma', vmin=vmin, vmax=vmax)\n",
    "ax[0].set_title('LRT cond. PMF'); ax[1].set_title('LRT joint PMF')\n",
    "\n",
    "err_lrt_P = torch.tensor([[frob_err(P_1D_lrt[t][i],P_1D_tru[t])**2 for i in range(T_range)] for t in range(num_trials)])\n",
    "err_lrt_Q = torch.tensor([[frob_err(Q_1D_lrt[t][i],Q_1D_tru[t])**2 for i in range(T_range)] for t in range(num_trials)])\n",
    "\n",
    "t = 0; i = 4\n",
    "fig = plt.figure(figsize=(2*5,4)); ax = fig.subplots(1,2); _ = [a.grid(1) for a in ax]; _ = [a.set_axisbelow(1) for a in ax]\n",
    "ax[0].plot(res_lrt[t][i]['admm_obj'],'-',c=vib_qual['red'])\n",
    "ax[1].plot(res_lrt[t][i]['admm_var'],'-',c=vib_qual['blue'])\n",
    "_ = [[a.set_xlabel('Iterations')] for a in ax]; ax[0].set_ylabel('Objective'); ax[1].set_ylabel('Variable difference')\n",
    "fig.tight_layout()\n",
    "\n",
    "fig = plt.figure(figsize=(2*5,4)); ax = fig.subplots(1,2); _ = [a.grid(1) for a in ax]; _ = [a.set_axisbelow(1) for a in ax]\n",
    "ax[0].plot(res_lrt[t][i]['admm_res'][0],'-',c=vib_qual['red'])\n",
    "ax[0].plot(res_lrt[t][i]['admm_res'][2],':',c=vib_qual['red'],alpha=.3)\n",
    "ax[1].plot(res_lrt[t][i]['admm_res'][1],'-',c=vib_qual['blue'])\n",
    "ax[1].plot(res_lrt[t][i]['admm_res'][3],':',c=vib_qual['blue'],alpha=.3)\n",
    "_ = [[a.set_xlabel('Iterations')] for a in ax]; ax[0].set_ylabel('Primal residual'); ax[1].set_ylabel('Dual residual')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err_lrt_r20_P_alt = torch.tensor([[norml1_err(P_1D_lrt[t][i], P_1D_tru[t]) for i in range(T_range)] for t in range(num_trials)]).mean(0)\n",
    "err_lrt_r20_P_alt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nuclear norm matrix estimation\n",
    "\n",
    "nnlrme_est_parallel = lambda nnlrm,Ph,args: nnlrm.estimate(Ph,args)\n",
    "\n",
    "nnlrm_args = {\n",
    "    'beta':None,\n",
    "    'gamma':None,\n",
    "    'eps_abs':eps_abs,\n",
    "    'eps_rel':eps_rel,\n",
    "    'eps_diff':eps_diff,\n",
    "    'max_itr':None,\n",
    "    'verbose':False\n",
    "}\n",
    "\n",
    "nnlrme = [[NucNormMatrixEstimator() for _ in range(T_range)] for _ in range(num_trials)]\n",
    "nnlrm_args['beta'] = 10\n",
    "nnlrm_args['gamma'] = 10\n",
    "nnlrm_args['max_itr'] = 5000\n",
    "results = Parallel(n_jobs=num_cpus)(delayed(nnlrme_est_parallel)( nnlrme[t][i],P_1D_obs[t][i],nnlrm_args ) for t in range(num_trials) for i in range(T_range))\n",
    "\n",
    "c = 0\n",
    "P_1D_nnlrm = [[None for _ in range(T_range)] for _ in range(num_trials)]\n",
    "Q_1D_nnlrm = [[None for _ in range(T_range)] for _ in range(num_trials)]\n",
    "res_nnlrm = [[None for _ in range(T_range)] for _ in range(num_trials)]\n",
    "for t in range(num_trials):\n",
    "    for i in range(T_range):\n",
    "        P_1D_nnlrm[t][i] = results[c][0].P\n",
    "        Q_1D_nnlrm[t][i] = results[c][0].Q\n",
    "        res_nnlrm[t][i] = results[c][1]\n",
    "        c+=1\n",
    "\n",
    "t = 0; i = -1\n",
    "fig = plt.figure(figsize=(2*4,4)); ax = fig.subplots(1,2); _ = [a.grid(1) for a in ax]; _ = [a.set_axisbelow(1) for a in ax]; _ = [a.axis('off') for a in ax]\n",
    "ax[0].imshow(P_1D_nnlrm[t][i],'plasma'); ax[1].imshow(Q_1D_nnlrm[t][i],'plasma')\n",
    "ax[0].set_title('NNLRM cond. PMF'); ax[1].set_title('NNLRM joint PMF')\n",
    "\n",
    "err_nnlrm_P = torch.tensor([[frob_err(P_1D_nnlrm[t][i],P_1D_tru[t])**2 for i in range(T_range)] for t in range(num_trials)])\n",
    "err_nnlrm_Q = torch.tensor([[frob_err(Q_1D_nnlrm[t][i],Q_1D_tru[t])**2 for i in range(T_range)] for t in range(num_trials)])\n",
    "\n",
    "t = 0; i = -1\n",
    "fig = plt.figure(figsize=(2*5,4)); ax = fig.subplots(1,2); _ = [a.grid(1) for a in ax]; _ = [a.set_axisbelow(1) for a in ax]\n",
    "ax[0].plot(res_nnlrm[t][i]['admm_obj'],'-',c=vib_qual['red'])\n",
    "ax[1].plot(res_nnlrm[t][i]['admm_var'],'-',c=vib_qual['blue'])\n",
    "_ = [[a.set_xlabel('Iterations')] for a in ax]; ax[0].set_ylabel('Objective'); ax[1].set_ylabel('Variable difference')\n",
    "fig.tight_layout()\n",
    "\n",
    "fig = plt.figure(figsize=(2*5,4)); ax = fig.subplots(1,2); _ = [a.grid(1) for a in ax]; _ = [a.set_axisbelow(1) for a in ax]\n",
    "ax[0].plot(res_nnlrm[t][i]['admm_res'][0],'-',c=vib_qual['red'])\n",
    "ax[0].plot(res_nnlrm[t][i]['admm_res'][2],':',c=vib_qual['red'],alpha=.3)\n",
    "ax[1].plot(res_nnlrm[t][i]['admm_res'][1],'-',c=vib_qual['blue'])\n",
    "ax[1].plot(res_nnlrm[t][i]['admm_res'][3],':',c=vib_qual['blue'],alpha=.3)\n",
    "_ = [[a.set_xlabel('Iterations')] for a in ax]; ax[0].set_ylabel('Primal residual'); ax[1].set_ylabel('Dual residual')\n",
    "fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Low-rank matrix estimation via DC algorithm\n",
    "\n",
    "dclrme_est_parallel = lambda dclrm,Ph,args: dclrm.estimate(Ph,args)\n",
    "\n",
    "dclrm_args = {\n",
    "    'K':None,\n",
    "    'c':None,\n",
    "    'alpha':None,\n",
    "    'beta':None,\n",
    "    'eps_abs':eps_abs,\n",
    "    'eps_rel':eps_rel,\n",
    "    'eps_diff':eps_diff,\n",
    "    'max_itr':None,\n",
    "    'admm_itr':1,\n",
    "    'verbose':False\n",
    "}\n",
    "\n",
    "dclrme = [[DCLowRankMatrixEstimator() for _ in range(T_range)] for _ in range(num_trials)]\n",
    "dclrm_args['K'] = 10\n",
    "dclrm_args['c'] = 10\n",
    "dclrm_args['alpha'] = .5\n",
    "dclrm_args['beta'] = 1\n",
    "dclrm_args['max_itr'] = 500\n",
    "dclrm_args['admm_itr'] = 1\n",
    "results = Parallel(n_jobs=num_cpus)(delayed(dclrme_est_parallel)( dclrme[t][i],P_1D_obs[t][i],dclrm_args ) for t in range(num_trials) for i in range(T_range))\n",
    "\n",
    "c = 0\n",
    "P_1D_dclrm = [[None for _ in range(T_range)] for _ in range(num_trials)]\n",
    "Q_1D_dclrm = [[None for _ in range(T_range)] for _ in range(num_trials)]\n",
    "res_dclrm = [[None for _ in range(T_range)] for _ in range(num_trials)]\n",
    "for t in range(num_trials):\n",
    "    for i in range(T_range):\n",
    "        P_1D_dclrm[t][i] = results[c][0].P\n",
    "        Q_1D_dclrm[t][i] = results[c][0].Q\n",
    "        res_dclrm[t][i] = results[c][1]\n",
    "        c+=1\n",
    "\n",
    "t = 0; i = -1\n",
    "fig = plt.figure(figsize=(2*4,4)); ax = fig.subplots(1,2); _ = [a.grid(1) for a in ax]; _ = [a.set_axisbelow(1) for a in ax]; _ = [a.axis('off') for a in ax]\n",
    "ax[0].imshow(P_1D_dclrm[t][i],'plasma'); ax[1].imshow(Q_1D_dclrm[t][i],'plasma')\n",
    "ax[0].set_title('DCLRM cond. PMF'); ax[1].set_title('DCLRM joint PMF')\n",
    "\n",
    "err_dclrm_P = torch.tensor([[frob_err(P_1D_dclrm[t][i],P_1D_tru[t])**2 for i in range(T_range)] for t in range(num_trials)])\n",
    "err_dclrm_Q = torch.tensor([[frob_err(Q_1D_dclrm[t][i],Q_1D_tru[t])**2 for i in range(T_range)] for t in range(num_trials)])\n",
    "\n",
    "t = 0; i = -1\n",
    "fig = plt.figure(figsize=(2*5,4)); ax = fig.subplots(1,2); _ = [a.grid(1) for a in ax]; _ = [a.set_axisbelow(1) for a in ax]\n",
    "ax[0].plot(res_dclrm[t][i]['admm_obj'],'-',c=vib_qual['red'])\n",
    "ax[1].plot(res_dclrm[t][i]['admm_var'],'-',c=vib_qual['blue'])\n",
    "_ = [[a.set_xlabel('Iterations')] for a in ax]; ax[0].set_ylabel('Objective'); ax[1].set_ylabel('Variable difference')\n",
    "fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spectral low-rank matrix estimation\n",
    "slrme_est_parallel = lambda slrm,Qh,K: slrm.estimate(Qh,K)\n",
    "\n",
    "slrme = [[SpecLowRankMatrixEstimator() for _ in range(T_range)] for _ in range(num_trials)]\n",
    "K_slrme = 20\n",
    "# results = [[slrme[t][i].estimate(Q_1D_obs[t][i],K_slrme) for i in range(T_range)] for t in range(num_trials)]\n",
    "results = Parallel(n_jobs=num_cpus)(delayed(slrme_est_parallel)( slrme[t][i],Q_1D_obs[t][i],K_slrme ) for t in range(num_trials) for i in range(T_range))\n",
    "\n",
    "c = 0\n",
    "P_1D_slrm = [[None for _ in range(T_range)] for _ in range(num_trials)]\n",
    "Q_1D_slrm = [[None for _ in range(T_range)] for _ in range(num_trials)]\n",
    "res_slrm = [[None for _ in range(T_range)] for _ in range(num_trials)]\n",
    "for t in range(num_trials):\n",
    "    for i in range(T_range):\n",
    "        P_1D_slrm[t][i] = results[c][0].P\n",
    "        Q_1D_slrm[t][i] = results[c][0].Q\n",
    "        res_slrm[t][i] = results[c][1]\n",
    "        c+=1\n",
    "\n",
    "i = -1\n",
    "i = 0\n",
    "fig = plt.figure(figsize=(2*4,4)); ax = fig.subplots(1,2); _ = [a.grid(1) for a in ax]; _ = [a.set_axisbelow(1) for a in ax]; _ = [a.axis('off') for a in ax]\n",
    "ax[0].imshow(P_1D_slrm[t][i],'plasma'); ax[1].imshow(Q_1D_slrm[t][i],'plasma')\n",
    "ax[0].set_title('slrm cond. PMF'); ax[1].set_title('slrm joint PMF')\n",
    "\n",
    "err_slrm_P = torch.tensor([[frob_err(P_1D_slrm[t][i],P_1D_tru[t])**2 for i in range(T_range)] for t in range(num_trials)])\n",
    "err_slrm_Q = torch.tensor([[frob_err(Q_1D_slrm[t][i],Q_1D_tru[t])**2 for i in range(T_range)] for t in range(num_trials)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the rank of conditional PMFs\n",
    "\n",
    "rank_obs = torch.tensor([[torch.linalg.matrix_rank(P_1D_obs[t][i]) for i in range(T_range)] for t in range(num_trials)]).to(torch.float)\n",
    "rank_lrt = torch.tensor([[torch.linalg.matrix_rank(P_1D_lrt[t][i]) for i in range(T_range)] for t in range(num_trials)]).to(torch.float)\n",
    "rank_nnlrm = torch.tensor([[torch.linalg.matrix_rank(P_1D_nnlrm[t][i]) for i in range(T_range)] for t in range(num_trials)]).to(torch.float)\n",
    "rank_dclrm = torch.tensor([[torch.linalg.matrix_rank(P_1D_dclrm[t][i]) for i in range(T_range)] for t in range(num_trials)]).to(torch.float)\n",
    "rank_slrm = torch.tensor([[torch.linalg.matrix_rank(P_1D_slrm[t][i]) for i in range(T_range)] for t in range(num_trials)]).to(torch.float)\n",
    "\n",
    "erank_obs = torch.tensor([[erank(P_1D_obs[t][i]) for i in range(T_range)] for t in range(num_trials)]).to(torch.float)\n",
    "erank_lrt = torch.tensor([[erank(P_1D_lrt[t][i]) for i in range(T_range)] for t in range(num_trials)]).to(torch.float)\n",
    "erank_nnlrm = torch.tensor([[erank(P_1D_nnlrm[t][i]) for i in range(T_range)] for t in range(num_trials)]).to(torch.float)\n",
    "erank_dclrm = torch.tensor([[erank(P_1D_dclrm[t][i]) for i in range(T_range)] for t in range(num_trials)]).to(torch.float)\n",
    "erank_slrm = torch.tensor([[erank(P_1D_slrm[t][i]) for i in range(T_range)] for t in range(num_trials)]).to(torch.float)\n",
    "\n",
    "erank_tru = torch.tensor([erank(P_1D_tru[t]) for t in range(num_trials)]).to(torch.float)\n",
    "rank_tru = torch.tensor([torch.linalg.matrix_rank(P_1D_tru[t]) for t in range(num_trials)]).to(torch.float)\n",
    "\n",
    "# Plot rank\n",
    "clr_list = [muted_qual['indigo'],muted_qual['rose'],muted_qual['sand'],muted_qual['purple'],muted_qual['teal'],muted_qual['wine']]\n",
    "methods = ['Emp.','LRT','NNLRM','DCLRM','SpecLRM','True']\n",
    "mkr_list = ['o','X','d','^','P','s']\n",
    "\n",
    "fig = plt.figure(); ax = fig.subplots(); ax.grid(1); ax.set_axisbelow(1)\n",
    "ax.semilogx( sampling_dims, [rank_tru.mean(0)]*T_range, '-', c=clr_list[-1], label=methods[-1], markersize=10, zorder = 3 )\n",
    "ax.semilogx( sampling_dims, rank_obs.mean(0), mkr_list[0], c=clr_list[0], label=methods[0], markersize=10, zorder = 4 )\n",
    "ax.semilogx( sampling_dims, rank_lrt.mean(0), mkr_list[1], c=clr_list[1], label=methods[1], markersize=10, zorder = 5 )\n",
    "ax.semilogx( sampling_dims, rank_nnlrm.mean(0), mkr_list[2], c=clr_list[2], label=methods[2], markersize=10, zorder = 4 )\n",
    "ax.semilogx( sampling_dims, rank_dclrm.mean(0), mkr_list[3], c=clr_list[3], label=methods[3], markersize=10, zorder = 4 )\n",
    "ax.semilogx( sampling_dims, rank_slrm.mean(0), mkr_list[4], c=clr_list[4], label=methods[4], markersize=10, zorder = 4 )\n",
    "ax.set_xlabel('No. samples'); ax.set_ylabel('Rank'); ax.legend()\n",
    "\n",
    "fig = plt.figure(); ax = fig.subplots(); ax.grid(1); ax.set_axisbelow(1)\n",
    "ax.semilogx( sampling_dims, [erank_tru.mean(0)]*T_range, '-', c=clr_list[-1], label=methods[-1], markersize=10, zorder = 3 )\n",
    "ax.semilogx( sampling_dims, erank_obs.mean(0), mkr_list[0], c=clr_list[0], label=methods[0], markersize=10, zorder = 4 )\n",
    "ax.semilogx( sampling_dims, erank_lrt.mean(0), mkr_list[1], c=clr_list[1], label=methods[1], markersize=10, zorder = 5 )\n",
    "ax.semilogx( sampling_dims, erank_nnlrm.mean(0), mkr_list[2], c=clr_list[2], label=methods[2], markersize=10, zorder = 4 )\n",
    "ax.semilogx( sampling_dims, erank_dclrm.mean(0), mkr_list[3], c=clr_list[3], label=methods[3], markersize=10, zorder = 4 )\n",
    "ax.semilogx( sampling_dims, erank_slrm.mean(0), mkr_list[4], c=clr_list[4], label=methods[4], markersize=10, zorder = 4 )\n",
    "ax.set_xlabel('No. samples'); ax.set_ylabel('Effective erank'); ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute error of conditional PMFs\n",
    "\n",
    "err_obs_P = torch.tensor([[normfrob_err(P_1D_obs[t][i],P_1D_tru[t])**2 for i in range(T_range)] for t in range(num_trials)])\n",
    "err_obs_Q = torch.tensor([[normfrob_err(Q_1D_obs[t][i],Q_1D_tru[t])**2 for i in range(T_range)] for t in range(num_trials)])\n",
    "err_lrt_P = torch.tensor([[normfrob_err(P_1D_lrt[t][i],P_1D_tru[t])**2 for i in range(T_range)] for t in range(num_trials)])\n",
    "err_lrt_Q = torch.tensor([[normfrob_err(Q_1D_lrt[t][i],Q_1D_tru[t])**2 for i in range(T_range)] for t in range(num_trials)])\n",
    "err_nnlrm_P = torch.tensor([[normfrob_err(P_1D_nnlrm[t][i],P_1D_tru[t])**2 for i in range(T_range)] for t in range(num_trials)])\n",
    "err_nnlrm_Q = torch.tensor([[normfrob_err(Q_1D_nnlrm[t][i],Q_1D_tru[t])**2 for i in range(T_range)] for t in range(num_trials)])\n",
    "err_dclrm_P = torch.tensor([[normfrob_err(P_1D_dclrm[t][i],P_1D_tru[t])**2 for i in range(T_range)] for t in range(num_trials)])\n",
    "err_dclrm_Q = torch.tensor([[normfrob_err(Q_1D_dclrm[t][i],Q_1D_tru[t])**2 for i in range(T_range)] for t in range(num_trials)])\n",
    "err_slrm_P = torch.tensor([[normfrob_err(P_1D_slrm[t][i],P_1D_tru[t])**2 for i in range(T_range)] for t in range(num_trials)])\n",
    "err_slrm_Q = torch.tensor([[normfrob_err(Q_1D_slrm[t][i],Q_1D_tru[t])**2 for i in range(T_range)] for t in range(num_trials)])\n",
    "\n",
    "# Plot error\n",
    "clr_list = [muted_qual['indigo'],muted_qual['rose'],muted_qual['sand'],muted_qual['purple'],muted_qual['teal'],muted_qual['wine']]\n",
    "methods = ['Emp.','LRT','NNLRM','DCLRM','SpecLRM','True']\n",
    "mkr_list = ['o','X','d','^','P','s']\n",
    "\n",
    "fig = plt.figure(); ax = fig.subplots(); ax.grid(1); ax.set_axisbelow(1)\n",
    "ax.semilogx( sampling_dims, err_obs_P.mean(0), mkr_list[0], c=clr_list[0], label=methods[0], markersize=10, zorder = 4 )\n",
    "ax.semilogx( sampling_dims, err_lrt_P.mean(0), mkr_list[1], c=clr_list[1], label=methods[1], markersize=10, zorder = 5 )\n",
    "ax.semilogx( sampling_dims, err_nnlrm_P.mean(0), mkr_list[2], c=clr_list[2], label=methods[2], markersize=10, zorder = 4 )\n",
    "ax.semilogx( sampling_dims, err_dclrm_P.mean(0), mkr_list[3], c=clr_list[3], label=methods[3], markersize=10, zorder = 4 )\n",
    "ax.semilogx( sampling_dims, err_slrm_P.mean(0), mkr_list[4], c=clr_list[4], label=methods[4], markersize=10, zorder = 4 )\n",
    "ax.set_xlabel('No. samples'); ax.set_ylabel('Error'); ax.legend()\n",
    "\n",
    "fig = plt.figure(); ax = fig.subplots(); ax.grid(1); ax.set_axisbelow(1)\n",
    "ax.semilogx( sampling_dims, err_lrt_P.mean(0), mkr_list[1], c=clr_list[1], label=methods[1], markersize=10, zorder = 5 )\n",
    "ax.semilogx( sampling_dims, err_nnlrm_P.mean(0), mkr_list[2], c=clr_list[2], label=methods[2], markersize=10, zorder = 4 )\n",
    "ax.semilogx( sampling_dims, err_dclrm_P.mean(0), mkr_list[3], c=clr_list[3], label=methods[3], markersize=10, zorder = 4 )\n",
    "ax.semilogx( sampling_dims, err_slrm_P.mean(0), mkr_list[4], c=clr_list[4], label=methods[4], markersize=10, zorder = 4 )\n",
    "ax.set_xlabel('No. samples'); ax.set_ylabel('Error'); ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute error of conditional PMFs\n",
    "\n",
    "err_obs_P = torch.tensor([[l1_err(P_1D_obs[t][i],P_1D_tru[t]) for i in range(T_range)] for t in range(num_trials)])\n",
    "err_obs_Q = torch.tensor([[l1_err(Q_1D_obs[t][i],Q_1D_tru[t]) for i in range(T_range)] for t in range(num_trials)])\n",
    "err_lrt_P = torch.tensor([[l1_err(P_1D_lrt[t][i],P_1D_tru[t]) for i in range(T_range)] for t in range(num_trials)])\n",
    "err_lrt_Q = torch.tensor([[l1_err(Q_1D_lrt[t][i],Q_1D_tru[t]) for i in range(T_range)] for t in range(num_trials)])\n",
    "err_nnlrm_P = torch.tensor([[l1_err(P_1D_nnlrm[t][i],P_1D_tru[t]) for i in range(T_range)] for t in range(num_trials)])\n",
    "err_nnlrm_Q = torch.tensor([[l1_err(Q_1D_nnlrm[t][i],Q_1D_tru[t]) for i in range(T_range)] for t in range(num_trials)])\n",
    "err_dclrm_P = torch.tensor([[l1_err(P_1D_dclrm[t][i],P_1D_tru[t]) for i in range(T_range)] for t in range(num_trials)])\n",
    "err_dclrm_Q = torch.tensor([[l1_err(Q_1D_dclrm[t][i],Q_1D_tru[t]) for i in range(T_range)] for t in range(num_trials)])\n",
    "err_slrm_P = torch.tensor([[l1_err(P_1D_slrm[t][i],P_1D_tru[t]) for i in range(T_range)] for t in range(num_trials)])\n",
    "err_slrm_Q = torch.tensor([[l1_err(Q_1D_slrm[t][i],Q_1D_tru[t]) for i in range(T_range)] for t in range(num_trials)])\n",
    "\n",
    "# Plot error\n",
    "clr_list = [muted_qual['indigo'],muted_qual['rose'],muted_qual['sand'],muted_qual['purple'],muted_qual['teal'],muted_qual['wine']]\n",
    "methods = ['Emp.','LRT','NNLRM','DCLRM','SpecLRM','True']\n",
    "mkr_list = ['o','X','d','^','P','s']\n",
    "\n",
    "fig = plt.figure(); ax = fig.subplots(); ax.grid(1); ax.set_axisbelow(1)\n",
    "ax.semilogx( sampling_dims, err_obs_P.mean(0), mkr_list[0], c=clr_list[0], label=methods[0], markersize=10, zorder = 4 )\n",
    "ax.semilogx( sampling_dims, err_lrt_P.mean(0), mkr_list[1], c=clr_list[1], label=methods[1], markersize=10, zorder = 5 )\n",
    "ax.semilogx( sampling_dims, err_nnlrm_P.mean(0), mkr_list[2], c=clr_list[2], label=methods[2], markersize=10, zorder = 4 )\n",
    "ax.semilogx( sampling_dims, err_dclrm_P.mean(0), mkr_list[3], c=clr_list[3], label=methods[3], markersize=10, zorder = 4 )\n",
    "ax.semilogx( sampling_dims, err_slrm_P.mean(0), mkr_list[4], c=clr_list[4], label=methods[4], markersize=10, zorder = 4 )\n",
    "ax.set_xlabel('No. samples'); ax.set_ylabel('Error'); ax.legend()\n",
    "\n",
    "fig = plt.figure(); ax = fig.subplots(); ax.grid(1); ax.set_axisbelow(1)\n",
    "ax.semilogx( sampling_dims, err_lrt_P.mean(0), mkr_list[1], c=clr_list[1], label=methods[1], markersize=10, zorder = 5 )\n",
    "ax.semilogx( sampling_dims, err_nnlrm_P.mean(0), mkr_list[2], c=clr_list[2], label=methods[2], markersize=10, zorder = 4 )\n",
    "ax.semilogx( sampling_dims, err_dclrm_P.mean(0), mkr_list[3], c=clr_list[3], label=methods[3], markersize=10, zorder = 4 )\n",
    "ax.semilogx( sampling_dims, err_slrm_P.mean(0), mkr_list[4], c=clr_list[4], label=methods[4], markersize=10, zorder = 4 )\n",
    "ax.set_xlabel('No. samples'); ax.set_ylabel('Error'); ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute error of conditional PMFs\n",
    "\n",
    "err_obs_P = torch.tensor([[sin_err(P_1D_obs[t][i],P_1D_tru[t]) for i in range(T_range)] for t in range(num_trials)])\n",
    "err_obs_Q = torch.tensor([[sin_err(Q_1D_obs[t][i],Q_1D_tru[t]) for i in range(T_range)] for t in range(num_trials)])\n",
    "err_lrt_P = torch.tensor([[sin_err(P_1D_lrt[t][i],P_1D_tru[t]) for i in range(T_range)] for t in range(num_trials)])\n",
    "err_lrt_Q = torch.tensor([[sin_err(Q_1D_lrt[t][i],Q_1D_tru[t]) for i in range(T_range)] for t in range(num_trials)])\n",
    "err_nnlrm_P = torch.tensor([[sin_err(P_1D_nnlrm[t][i],P_1D_tru[t]) for i in range(T_range)] for t in range(num_trials)])\n",
    "err_nnlrm_Q = torch.tensor([[sin_err(Q_1D_nnlrm[t][i],Q_1D_tru[t]) for i in range(T_range)] for t in range(num_trials)])\n",
    "err_dclrm_P = torch.tensor([[sin_err(P_1D_dclrm[t][i],P_1D_tru[t]) for i in range(T_range)] for t in range(num_trials)])\n",
    "err_dclrm_Q = torch.tensor([[sin_err(Q_1D_dclrm[t][i],Q_1D_tru[t]) for i in range(T_range)] for t in range(num_trials)])\n",
    "err_slrm_P = torch.tensor([[sin_err(P_1D_slrm[t][i],P_1D_tru[t]) for i in range(T_range)] for t in range(num_trials)])\n",
    "err_slrm_Q = torch.tensor([[sin_err(Q_1D_slrm[t][i],Q_1D_tru[t]) for i in range(T_range)] for t in range(num_trials)])\n",
    "\n",
    "# Plot error\n",
    "clr_list = [muted_qual['indigo'],muted_qual['rose'],muted_qual['sand'],muted_qual['purple'],muted_qual['teal'],muted_qual['wine']]\n",
    "methods = ['Emp.','LRT','NNLRM','DCLRM','SpecLRM','True']\n",
    "mkr_list = ['o','X','d','^','P','s']\n",
    "\n",
    "fig = plt.figure(); ax = fig.subplots(); ax.grid(1); ax.set_axisbelow(1)\n",
    "ax.semilogx( sampling_dims, err_obs_P.mean(0), mkr_list[0], c=clr_list[0], label=methods[0], markersize=10, zorder = 4 )\n",
    "ax.semilogx( sampling_dims, err_lrt_P.mean(0), mkr_list[1], c=clr_list[1], label=methods[1], markersize=10, zorder = 5 )\n",
    "ax.semilogx( sampling_dims, err_nnlrm_P.mean(0), mkr_list[2], c=clr_list[2], label=methods[2], markersize=10, zorder = 4 )\n",
    "ax.semilogx( sampling_dims, err_dclrm_P.mean(0), mkr_list[3], c=clr_list[3], label=methods[3], markersize=10, zorder = 4 )\n",
    "ax.semilogx( sampling_dims, err_slrm_P.mean(0), mkr_list[4], c=clr_list[4], label=methods[4], markersize=10, zorder = 4 )\n",
    "ax.set_xlabel('No. samples'); ax.set_ylabel('Error'); ax.legend()\n",
    "\n",
    "fig = plt.figure(); ax = fig.subplots(); ax.grid(1); ax.set_axisbelow(1)\n",
    "ax.semilogx( sampling_dims, err_lrt_P.mean(0), mkr_list[1], c=clr_list[1], label=methods[1], markersize=10, zorder = 5 )\n",
    "ax.semilogx( sampling_dims, err_nnlrm_P.mean(0), mkr_list[2], c=clr_list[2], label=methods[2], markersize=10, zorder = 4 )\n",
    "ax.semilogx( sampling_dims, err_dclrm_P.mean(0), mkr_list[3], c=clr_list[3], label=methods[3], markersize=10, zorder = 4 )\n",
    "ax.semilogx( sampling_dims, err_slrm_P.mean(0), mkr_list[4], c=clr_list[4], label=methods[4], markersize=10, zorder = 4 )\n",
    "ax.set_xlabel('No. samples'); ax.set_ylabel('Error'); ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_filtered_error(observed, true):\n",
    "    mask = true != 0\n",
    "    return (normfrob_err(observed * mask, true) ** 2)\n",
    "\n",
    "# Calculate errors for P and Q matrices, considering only non-zero true values\n",
    "err_obs_P = torch.tensor([[compute_filtered_error(P_1D_obs[t][i], P_1D_tru[t]) for i in range(T_range)] for t in range(num_trials)])\n",
    "err_obs_Q = torch.tensor([[compute_filtered_error(Q_1D_obs[t][i], Q_1D_tru[t]) for i in range(T_range)] for t in range(num_trials)])\n",
    "err_lrt_P = torch.tensor([[compute_filtered_error(P_1D_lrt[t][i], P_1D_tru[t]) for i in range(T_range)] for t in range(num_trials)])\n",
    "err_lrt_Q = torch.tensor([[compute_filtered_error(Q_1D_lrt[t][i], Q_1D_tru[t]) for i in range(T_range)] for t in range(num_trials)])\n",
    "err_nnlrm_P = torch.tensor([[compute_filtered_error(P_1D_nnlrm[t][i], P_1D_tru[t]) for i in range(T_range)] for t in range(num_trials)])\n",
    "err_nnlrm_Q = torch.tensor([[compute_filtered_error(Q_1D_nnlrm[t][i], Q_1D_tru[t]) for i in range(T_range)] for t in range(num_trials)])\n",
    "err_dclrm_P = torch.tensor([[compute_filtered_error(P_1D_dclrm[t][i], P_1D_tru[t]) for i in range(T_range)] for t in range(num_trials)])\n",
    "err_dclrm_Q = torch.tensor([[compute_filtered_error(Q_1D_dclrm[t][i], Q_1D_tru[t]) for i in range(T_range)] for t in range(num_trials)])\n",
    "err_slrm_P = torch.tensor([[compute_filtered_error(P_1D_slrm[t][i], P_1D_tru[t]) for i in range(T_range)] for t in range(num_trials)])\n",
    "err_slrm_Q = torch.tensor([[compute_filtered_error(Q_1D_slrm[t][i], Q_1D_tru[t]) for i in range(T_range)] for t in range(num_trials)])\n",
    "\n",
    "\n",
    "# Plot error\n",
    "clr_list = [muted_qual['indigo'],muted_qual['rose'],muted_qual['sand'],muted_qual['purple'],muted_qual['teal'],muted_qual['wine']]\n",
    "methods = ['Emp.','LRT','NNLRM','DCLRM','SpecLRM','True']\n",
    "mkr_list = ['o','X','d','^','P','s']\n",
    "\n",
    "fig = plt.figure(); ax = fig.subplots(); ax.grid(1); ax.set_axisbelow(1)\n",
    "ax.semilogx( sampling_dims, err_obs_P.mean(0), mkr_list[0], c=clr_list[0], label=methods[0], markersize=10, zorder = 4 )\n",
    "ax.semilogx( sampling_dims, err_lrt_P.mean(0), mkr_list[1], c=clr_list[1], label=methods[1], markersize=10, zorder = 5 )\n",
    "ax.semilogx( sampling_dims, err_nnlrm_P.mean(0), mkr_list[2], c=clr_list[2], label=methods[2], markersize=10, zorder = 4 )\n",
    "ax.semilogx( sampling_dims, err_dclrm_P.mean(0), mkr_list[3], c=clr_list[3], label=methods[3], markersize=10, zorder = 4 )\n",
    "ax.semilogx( sampling_dims, err_slrm_P.mean(0), mkr_list[4], c=clr_list[4], label=methods[4], markersize=10, zorder = 4 )\n",
    "ax.set_xlabel('No. samples'); ax.set_ylabel('Error'); ax.legend()\n",
    "\n",
    "fig = plt.figure(); ax = fig.subplots(); ax.grid(1); ax.set_axisbelow(1)\n",
    "ax.semilogx( sampling_dims, err_lrt_P.mean(0), mkr_list[1], c=clr_list[1], label=methods[1], markersize=10, zorder = 5 )\n",
    "ax.semilogx( sampling_dims, err_nnlrm_P.mean(0), mkr_list[2], c=clr_list[2], label=methods[2], markersize=10, zorder = 4 )\n",
    "ax.semilogx( sampling_dims, err_dclrm_P.mean(0), mkr_list[3], c=clr_list[3], label=methods[3], markersize=10, zorder = 4 )\n",
    "ax.semilogx( sampling_dims, err_slrm_P.mean(0), mkr_list[4], c=clr_list[4], label=methods[4], markersize=10, zorder = 4 )\n",
    "ax.set_xlabel('No. samples'); ax.set_ylabel('Error'); ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_filtered_error(observed, true):\n",
    "    mask = true != 0\n",
    "    return (l1_err(observed * mask, true))\n",
    "\n",
    "# Calculate errors for P and Q matrices, considering only non-zero true values\n",
    "err_obs_P = torch.tensor([[compute_filtered_error(P_1D_obs[t][i], P_1D_tru[t]) for i in range(T_range)] for t in range(num_trials)])\n",
    "err_obs_Q = torch.tensor([[compute_filtered_error(Q_1D_obs[t][i], Q_1D_tru[t]) for i in range(T_range)] for t in range(num_trials)])\n",
    "err_lrt_P = torch.tensor([[compute_filtered_error(P_1D_lrt[t][i], P_1D_tru[t]) for i in range(T_range)] for t in range(num_trials)])\n",
    "err_lrt_Q = torch.tensor([[compute_filtered_error(Q_1D_lrt[t][i], Q_1D_tru[t]) for i in range(T_range)] for t in range(num_trials)])\n",
    "err_nnlrm_P = torch.tensor([[compute_filtered_error(P_1D_nnlrm[t][i], P_1D_tru[t]) for i in range(T_range)] for t in range(num_trials)])\n",
    "err_nnlrm_Q = torch.tensor([[compute_filtered_error(Q_1D_nnlrm[t][i], Q_1D_tru[t]) for i in range(T_range)] for t in range(num_trials)])\n",
    "err_dclrm_P = torch.tensor([[compute_filtered_error(P_1D_dclrm[t][i], P_1D_tru[t]) for i in range(T_range)] for t in range(num_trials)])\n",
    "err_dclrm_Q = torch.tensor([[compute_filtered_error(Q_1D_dclrm[t][i], Q_1D_tru[t]) for i in range(T_range)] for t in range(num_trials)])\n",
    "err_slrm_P = torch.tensor([[compute_filtered_error(P_1D_slrm[t][i], P_1D_tru[t]) for i in range(T_range)] for t in range(num_trials)])\n",
    "err_slrm_Q = torch.tensor([[compute_filtered_error(Q_1D_slrm[t][i], Q_1D_tru[t]) for i in range(T_range)] for t in range(num_trials)])\n",
    "\n",
    "\n",
    "# Plot error\n",
    "clr_list = [muted_qual['indigo'],muted_qual['rose'],muted_qual['sand'],muted_qual['purple'],muted_qual['teal'],muted_qual['wine']]\n",
    "methods = ['Emp.','LRT','NNLRM','DCLRM','SpecLRM','True']\n",
    "mkr_list = ['o','X','d','^','P','s']\n",
    "\n",
    "fig = plt.figure(); ax = fig.subplots(); ax.grid(1); ax.set_axisbelow(1)\n",
    "ax.semilogx( sampling_dims, err_obs_P.mean(0), mkr_list[0], c=clr_list[0], label=methods[0], markersize=10, zorder = 4 )\n",
    "ax.semilogx( sampling_dims, err_lrt_P.mean(0), mkr_list[1], c=clr_list[1], label=methods[1], markersize=10, zorder = 5 )\n",
    "ax.semilogx( sampling_dims, err_nnlrm_P.mean(0), mkr_list[2], c=clr_list[2], label=methods[2], markersize=10, zorder = 4 )\n",
    "ax.semilogx( sampling_dims, err_dclrm_P.mean(0), mkr_list[3], c=clr_list[3], label=methods[3], markersize=10, zorder = 4 )\n",
    "ax.semilogx( sampling_dims, err_slrm_P.mean(0), mkr_list[4], c=clr_list[4], label=methods[4], markersize=10, zorder = 4 )\n",
    "ax.set_xlabel('No. samples'); ax.set_ylabel('Error'); ax.legend()\n",
    "\n",
    "fig = plt.figure(); ax = fig.subplots(); ax.grid(1); ax.set_axisbelow(1)\n",
    "ax.semilogx( sampling_dims, err_lrt_P.mean(0), mkr_list[1], c=clr_list[1], label=methods[1], markersize=10, zorder = 5 )\n",
    "ax.semilogx( sampling_dims, err_nnlrm_P.mean(0), mkr_list[2], c=clr_list[2], label=methods[2], markersize=10, zorder = 4 )\n",
    "ax.semilogx( sampling_dims, err_dclrm_P.mean(0), mkr_list[3], c=clr_list[3], label=methods[3], markersize=10, zorder = 4 )\n",
    "ax.semilogx( sampling_dims, err_slrm_P.mean(0), mkr_list[4], c=clr_list[4], label=methods[4], markersize=10, zorder = 4 )\n",
    "ax.set_xlabel('No. samples'); ax.set_ylabel('Error'); ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - Estimation (Experiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chain(df, n):\n",
    "    M_ten = np.zeros((n_periods, n_locations))  # Marginal probability of pickup states\n",
    "    Q_ten = np.zeros((n_periods, n_locations, n_periods, n_locations))  # Joint distribution of transitions\n",
    "\n",
    "    for _, row in df.sample(n=n).iterrows():\n",
    "        pu_period_idx = int(row['PUhour'])  # Pickup hour index (0-23)\n",
    "        pu_loc_idx = int(row['PULocationID']) - 1  # Assuming LocationID is 1-indexed\n",
    "        do_period_idx = int(row['DOhour'])  # Dropoff hour index (0-23)\n",
    "        do_loc_idx = int(row['DOLocationID']) - 1  # Assuming LocationID is 1-indexed\n",
    "\n",
    "        M_ten[pu_period_idx, pu_loc_idx] += 1\n",
    "\n",
    "        Q_ten[pu_period_idx, pu_loc_idx, do_period_idx, do_loc_idx] += 1\n",
    "\n",
    "    Q_ten_sum = Q_ten.sum()\n",
    "    if Q_ten_sum > 0:\n",
    "        Q_ten = Q_ten / Q_ten_sum\n",
    "    Q_mat = Q_ten.reshape(n_periods * n_locations, n_periods * n_locations)\n",
    "\n",
    "    P_sum = Q_ten.sum(axis=(2, 3), keepdims=True)\n",
    "    P_sum[P_sum == 0] = 1\n",
    "    P_ten = Q_ten / P_sum\n",
    "    P_mat = P_ten.reshape(n_periods * n_locations, n_periods * n_locations)\n",
    "    return P_ten, P_mat, Q_ten, Q_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_mat = torch.tensor(P_mat).float()\n",
    "Q_mat = torch.tensor(Q_mat).float()\n",
    "M_vec = torch.tensor(M_vec).float()\n",
    "\n",
    "P_ten = torch.tensor(P_ten).float()\n",
    "Q_ten = torch.tensor(Q_ten).float()\n",
    "M_ten = torch.tensor(M_ten).float()\n",
    "\n",
    "num_trials = 5\n",
    "N = torch.tensor(P_ten.shape[:2]) # No. states per dimension\n",
    "\n",
    "mcs = []\n",
    "P_tru = []; Q_tru = []; P_1D_tru = []; Q_1D_tru = []\n",
    "for t in range(num_trials):\n",
    "    P_tru.append(P_ten.reshape(tuple(N.repeat(2))).clone())\n",
    "    Q_tru.append(Q_ten.reshape(tuple(N.repeat(2))).clone())\n",
    "    P_1D_tru.append(P_mat.clone())\n",
    "    Q_1D_tru.append(Q_mat.clone())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_dims = np.logspace(3, 5, 5).astype(int)\n",
    "P_1D_obs, Q_1D_obs = [[] for _ in range(num_trials)], [[] for _ in range(num_trials)]\n",
    "P_obs, Q_obs = [[] for _ in range(num_trials)], [[] for _ in range(num_trials)]\n",
    "for t in range(num_trials):\n",
    "    for n in sampling_dims:\n",
    "        P_ten, P_mat, Q_ten, Q_mat = get_chain(df_trips_manhattan, n)\n",
    "\n",
    "        P_mat = torch.tensor(P_mat).float()\n",
    "        Q_mat = torch.tensor(Q_mat).float()\n",
    "        P_ten = torch.tensor(P_ten).float()\n",
    "        Q_ten = torch.tensor(Q_ten).float()\n",
    "\n",
    "        P_1D_obs[t].append(P_mat)\n",
    "        Q_1D_obs[t].append(Q_mat)\n",
    "        P_obs[t].append(P_ten)\n",
    "        Q_obs[t].append(Q_ten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1000\n",
    "num_cpus = os.cpu_count() // 2\n",
    "np.random.seed(SEED)\n",
    "os.environ['OMP_NUM_THREADS'] = str(num_cpus)\n",
    "verbose = False\n",
    "\n",
    "T_range = len(sampling_dims)\n",
    "\n",
    "eps_abs = 1e-7\n",
    "eps_rel = 1e-7\n",
    "eps_diff = 1e-7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Low-rank tensor estimation\n",
    "# res = []\n",
    "\n",
    "eps_abs = 1e-7\n",
    "eps_rel = 1e-7\n",
    "eps_diff = 1e-7\n",
    "\n",
    "for r in [2, 10, 20]:\n",
    "    lrte_est_parallel = lambda lrte, Qh, lrt_args: lrte.estimate(Qh, lrt_args)\n",
    "\n",
    "    lrt_args = {\n",
    "        'K':None,\n",
    "        'beta':None,\n",
    "        'eps_abs':eps_abs,\n",
    "        'eps_rel':eps_rel,\n",
    "        'eps_diff':eps_diff,\n",
    "        'max_itr':None,\n",
    "        'verbose':verbose,\n",
    "        'MARG_CONST':True,\n",
    "        'ACCEL':True\n",
    "    }\n",
    "\n",
    "    lrte = [[LowRankTensorEstimator() for _ in range(T_range)] for _ in range(num_trials)]\n",
    "    # lrt_args['K'] = 50\n",
    "    lrt_args['K'] = r\n",
    "    lrt_args['beta'] = .01 # .01\n",
    "    lrt_args['max_itr'] = 40_000 # 5_000\n",
    "    results = Parallel(n_jobs=num_cpus)(delayed(lrte_est_parallel)( lrte[t][i],Q_obs[t][i],lrt_args ) for t in range(num_trials) for i in range(T_range))\n",
    "\n",
    "    c = 0\n",
    "    P_1D_lrt = [[None for _ in range(T_range)] for _ in range(num_trials)]\n",
    "    Q_1D_lrt = [[None for _ in range(T_range)] for _ in range(num_trials)]\n",
    "    res_lrt = [[None for _ in range(T_range)] for _ in range(num_trials)]\n",
    "    for t in range(num_trials):\n",
    "        for i in range(T_range):\n",
    "            P_1D_lrt[t][i] = results[c][0].P_1D\n",
    "            Q_1D_lrt[t][i] = results[c][0].Q_1D\n",
    "            res_lrt[t][i] = results[c][1]\n",
    "            c+=1\n",
    "    err = torch.tensor([[norml1_err(P_1D_lrt[t][i], P_1D_tru[t]) for i in range(T_range)] for t in range(num_trials)]).mean(0)\n",
    "    res.append(err.detach().numpy())\n",
    "res = np.array(res)\n",
    "np.save('results/lrt.npy', res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 2\n",
    "\n",
    "eps_abs = 1e-7\n",
    "eps_rel = 1e-7\n",
    "eps_diff = 1e-7\n",
    "\n",
    "args = {\n",
    "    'K': 50,\n",
    "    'beta':0.01,\n",
    "    'eps_abs':eps_abs,\n",
    "    'eps_rel':eps_rel,\n",
    "    'eps_diff':eps_diff,\n",
    "    'max_itr':40_000,\n",
    "    'verbose':verbose,\n",
    "    'MARG_CONST':True,\n",
    "    'ACCEL':True\n",
    "}\n",
    "\n",
    "model = LowRankTensorEstimator()\n",
    "model.estimate(Q_obs[0][idx], args)\n",
    "\n",
    "e_r50 = norml1_err(model.P_1D, P_1D_tru[0])\n",
    "e_r50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nuclear norm matrix estimation\n",
    "\n",
    "eps_abs = 1e-6\n",
    "eps_rel = 1e-6\n",
    "eps_diff = 1e-6\n",
    "\n",
    "res = []\n",
    "for g in [0.1, 1.0]:\n",
    "    nnlrme_est_parallel = lambda nnlrm,Ph,args: nnlrm.estimate(Ph,args)\n",
    "\n",
    "    nnlrm_args = {\n",
    "        'beta':None,\n",
    "        'gamma':None,\n",
    "        'eps_abs':eps_abs,\n",
    "        'eps_rel':eps_rel,\n",
    "        'eps_diff':eps_diff,\n",
    "        'max_itr':None,\n",
    "        'verbose':False\n",
    "    }\n",
    "\n",
    "    nnlrme = [[NucNormMatrixEstimator() for _ in range(T_range)] for _ in range(num_trials)]\n",
    "    nnlrm_args['beta'] = 10\n",
    "    nnlrm_args['gamma'] = g\n",
    "    nnlrm_args['max_itr'] = 5000\n",
    "    results = Parallel(n_jobs=num_cpus)(delayed(nnlrme_est_parallel)( nnlrme[t][i],P_1D_obs[t][i],nnlrm_args ) for t in range(num_trials) for i in range(T_range))\n",
    "\n",
    "    c = 0\n",
    "    P_1D_nnlrm = [[None for _ in range(T_range)] for _ in range(num_trials)]\n",
    "    Q_1D_nnlrm = [[None for _ in range(T_range)] for _ in range(num_trials)]\n",
    "    res_nnlrm = [[None for _ in range(T_range)] for _ in range(num_trials)]\n",
    "    for t in range(num_trials):\n",
    "        for i in range(T_range):\n",
    "            P_1D_nnlrm[t][i] = results[c][0].P\n",
    "            Q_1D_nnlrm[t][i] = results[c][0].Q\n",
    "            res_nnlrm[t][i] = results[c][1]\n",
    "            c+=1\n",
    "    err = torch.tensor([[norml1_err(P_1D_nnlrm[t][i], P_1D_tru[t]) for i in range(T_range)] for t in range(num_trials)]).mean(0)\n",
    "    res.append(err.detach().numpy())\n",
    "res = np.array(res)\n",
    "np.save('results/nnlrm.npy', res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Low-rank matrix estimation via DC algorithm\n",
    "eps_abs = 1e-6\n",
    "eps_rel = 1e-6\n",
    "eps_diff = 1e-6\n",
    "\n",
    "res = []\n",
    "for r in [5, 10]:\n",
    "    dclrme_est_parallel = lambda dclrm,Ph,args: dclrm.estimate(Ph,args)\n",
    "\n",
    "    dclrm_args = {\n",
    "        'K':None,\n",
    "        'c':None,\n",
    "        'alpha':None,\n",
    "        'beta':None,\n",
    "        'eps_abs':eps_abs,\n",
    "        'eps_rel':eps_rel,\n",
    "        'eps_diff':eps_diff,\n",
    "        'max_itr':None,\n",
    "        'admm_itr':1,\n",
    "        'verbose':False\n",
    "    }\n",
    "\n",
    "    dclrme = [[DCLowRankMatrixEstimator() for _ in range(T_range)] for _ in range(num_trials)]\n",
    "    dclrm_args['K'] = r\n",
    "    dclrm_args['c'] = 5\n",
    "    dclrm_args['alpha'] = .5\n",
    "    dclrm_args['beta'] = 1\n",
    "    dclrm_args['max_itr'] = 500\n",
    "    dclrm_args['admm_itr'] = 1\n",
    "    results = Parallel(n_jobs=num_cpus)(delayed(dclrme_est_parallel)( dclrme[t][i],P_1D_obs[t][i],dclrm_args ) for t in range(num_trials) for i in range(T_range))\n",
    "\n",
    "    c = 0\n",
    "    P_1D_dclrm = [[None for _ in range(T_range)] for _ in range(num_trials)]\n",
    "    Q_1D_dclrm = [[None for _ in range(T_range)] for _ in range(num_trials)]\n",
    "    res_dclrm = [[None for _ in range(T_range)] for _ in range(num_trials)]\n",
    "    for t in range(num_trials):\n",
    "        for i in range(T_range):\n",
    "            P_1D_dclrm[t][i] = results[c][0].P\n",
    "            Q_1D_dclrm[t][i] = results[c][0].Q\n",
    "            res_dclrm[t][i] = results[c][1]\n",
    "            c+=1\n",
    "    err = torch.tensor([[norml1_err(P_1D_dclrm[t][i], P_1D_tru[t]) for i in range(T_range)] for t in range(num_trials)]).mean(0)\n",
    "    res.append(err.detach().numpy())\n",
    "res = np.array(res)\n",
    "np.save('results/dclrm.npy', res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "for r in [1, 5, 10, 20]:\n",
    "    slrme_est_parallel = lambda slrm,Qh,K: slrm.estimate(Qh,K)\n",
    "\n",
    "    slrme = [[SpecLowRankMatrixEstimator() for _ in range(T_range)] for _ in range(num_trials)]\n",
    "    K_slrme = r\n",
    "    # results = [[slrme[t][i].estimate(Q_1D_obs[t][i],K_slrme) for i in range(T_range)] for t in range(num_trials)]\n",
    "    results = Parallel(n_jobs=num_cpus)(delayed(slrme_est_parallel)( slrme[t][i],Q_1D_obs[t][i],K_slrme ) for t in range(num_trials) for i in range(T_range))\n",
    "\n",
    "    c = 0\n",
    "    P_1D_slrm = [[None for _ in range(T_range)] for _ in range(num_trials)]\n",
    "    Q_1D_slrm = [[None for _ in range(T_range)] for _ in range(num_trials)]\n",
    "    res_slrm = [[None for _ in range(T_range)] for _ in range(num_trials)]\n",
    "    for t in range(num_trials):\n",
    "        for i in range(T_range):\n",
    "            P_1D_slrm[t][i] = results[c][0].P\n",
    "            Q_1D_slrm[t][i] = results[c][0].Q\n",
    "            res_slrm[t][i] = results[c][1]\n",
    "            c+=1\n",
    "    err = torch.tensor([[norml1_err(P_1D_slrm[t][i], P_1D_tru[t]) for i in range(T_range)] for t in range(num_trials)]).mean(0)\n",
    "    res.append(err.detach().numpy())\n",
    "res = np.array(res)\n",
    "np.save('results/slrm.npy', res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 - Create data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrt = np.load('results/lrt.npy')\n",
    "dclrm = np.load('results/dclrm.npy')\n",
    "nnlrm = np.load('results/nnlrm.npy')\n",
    "slrm = np.load('results/slrm.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrt_2 = lrt[0].tolist() # 288 params\n",
    "lrt_10 = lrt[1].tolist() # 1440 params\n",
    "lrt_20 = lrt[2].tolist() # 2880 params\n",
    "lrt_50 = lrt[3].tolist() # 7200 params\n",
    "\n",
    "dclrm_5 = dclrm[0].tolist()\n",
    "dclrm_10 = dclrm[1].tolist()\n",
    "\n",
    "nnlrm_01 = nnlrm[0].tolist()\n",
    "nnlrm_1 = nnlrm[1].tolist()\n",
    "\n",
    "slrm_1 = slrm[0].tolist() # 792 params\n",
    "slrm_5 = slrm[1].tolist() # 3960 params\n",
    "slrm_10 = slrm[2].tolist() # 7920 params\n",
    "slrm_20 = slrm[3].tolist() # 15840 params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ny_sampling = pd.DataFrame({\n",
    "    'sampling': sampling_dims,\n",
    "    'err_lrt_r10': lrt_10,\n",
    "    'err_lrt_r20': lrt_20,\n",
    "    'err_nnlrm_01_P': nnlrm_01,\n",
    "    'err_nnlrm_1_P': nnlrm_1,\n",
    "    'err_dclrm_5_P': dclrm_5,\n",
    "    'err_dclrm_10_P': dclrm_10,\n",
    "    'err_slrm_r5_P': slrm_5,\n",
    "    'err_slrm_r10_P': slrm_10,\n",
    "}).astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ny_sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ny_sampling.to_csv('results/5_ny_sampling.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks_slrm = [1, 5, 10, 20]\n",
    "ranks_lrt = [2, 10, 20, 50]\n",
    "\n",
    "params_slrm = [2 * 66 * 6 * k for k in ranks_slrm]\n",
    "params_lrt = [(66 + 6 + 66 + 6)*k for k in ranks_lrt]\n",
    "\n",
    "idx = 2\n",
    "\n",
    "err_rank_lrt = [\n",
    "    lrt_2[idx],\n",
    "    lrt_10[idx],\n",
    "    lrt_20[idx],\n",
    "    lrt_50[idx],\n",
    "]\n",
    "\n",
    "err_rank_slrm = [\n",
    "    slrm_1[idx],\n",
    "    slrm_5[idx],\n",
    "    slrm_10[idx],\n",
    "    slrm_20[idx],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ny_params = pd.DataFrame({\n",
    "    'params_lrt': params_lrt,\n",
    "    'params_slrm': params_slrm,\n",
    "    'err_rank_lrt': err_rank_lrt,\n",
    "    'err_rank_slrm': err_rank_slrm,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ny_params.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ny_params.to_csv('results/6_ny_params.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lrtmc-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
